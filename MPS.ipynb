{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from matplotlib import pyplot as plt "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "use_gpu"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MPS model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert hid_dim % n_heads == 0\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = hid_dim // n_heads\n",
    "        \n",
    "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "\n",
    "        \n",
    "    def forward(self, query, key, value):\n",
    "        \n",
    "        batch_size = query.shape[0]\n",
    "        \n",
    "        #query = [batch size, query len, hid dim]\n",
    "        #key = [batch size, key len, hid dim]\n",
    "        #value = [batch size, value len, hid dim]\n",
    "                \n",
    "        Q = self.fc_q(query)\n",
    "        K = self.fc_k(key)\n",
    "        V = self.fc_v(value)\n",
    "\n",
    "        #Q = [batch size, query len, hid dim]\n",
    "        #K = [batch size, key len, hid dim]\n",
    "        #V = [batch size, value len, hid dim]\n",
    "\n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        \n",
    "        #Q = [batch size, n heads, query len, head dim]\n",
    "        #K = [batch size, n heads, key len, head dim]\n",
    "        #V = [batch size, n heads, value len, head dim]\n",
    "                \n",
    "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "        \n",
    "        #energy = [batch size, n heads, query len, key len]\n",
    "        \n",
    "        attention = torch.softmax(energy, dim = -1)\n",
    "                \n",
    "        #attention = [batch size, n heads, query len, key len]\n",
    "                \n",
    "        x = torch.matmul(self.dropout(attention), V)\n",
    "        \n",
    "        #x = [batch size, n heads, query len, head dim]\n",
    "        \n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        \n",
    "        #x = [batch size, query len, n heads, head dim]\n",
    "        \n",
    "        x = x.view(batch_size, -1, self.hid_dim)\n",
    "        \n",
    "        #x = [batch size, query len, hid dim]\n",
    "        \n",
    "        x = self.fc_o(x)\n",
    "        \n",
    "        #x = [batch size, query len, hid dim]\n",
    "        \n",
    "        return x, attention"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class FeedforwardLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
    "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #x = [batch size, seq len, hid dim]\n",
    "        \n",
    "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
    "        \n",
    "        #x = [batch size, seq len, pf dim]\n",
    "        \n",
    "        x = self.fc_2(x)\n",
    "        \n",
    "        #x = [batch size, seq len, hid dim]\n",
    "        \n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 hid_dim, \n",
    "                 n_heads, \n",
    "                 pf_dim,  \n",
    "                 dropout, \n",
    "                 device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.feedforward = FeedforwardLayer(hid_dim, pf_dim,dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [batch size, src len, hid dim]\n",
    "                \n",
    "        #self attention\n",
    "        _src, _ = self.self_attention(src, src, src)\n",
    "        \n",
    "        #dropout, residual connection and layer norm\n",
    "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
    "        \n",
    "        #src = [batch size, src len, hid dim]\n",
    "        \n",
    "        # feedforward\n",
    "        _src = self.feedforward(src)\n",
    "        \n",
    "        #dropout, residual and layer norm\n",
    "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
    "        \n",
    "        #src = [batch size, src len, hid dim]\n",
    "        return src"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    # 输入数据的维度为(input_dim, hid_dim)\n",
    "    # pf_dim 是ff的中间层维度\n",
    "    def __init__(self, \n",
    "                 input_dim,\n",
    "                 hid_dim, \n",
    "                 n_layers, \n",
    "                 n_heads, \n",
    "                 pf_dim,\n",
    "                 dropout, \n",
    "                 device):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        :param input_dim: 输入的数据长度len\n",
    "        :param output_dim：\n",
    "        :param hid_dim: 输入的数据维度dim\n",
    "        :param n_layers: transformer的层数\n",
    "        :param n_heads: 多头attention的数量\n",
    "        :param pf_dim: feed forward的中间层维度\n",
    "        :param dropout:\n",
    "        :param device\n",
    "       \n",
    "        \"\"\"\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "        self.layers = nn.ModuleList([TransformerEncoderLayer(hid_dim, \n",
    "                                                  n_heads, \n",
    "                                                  pf_dim,\n",
    "                                                  dropout, \n",
    "                                                  device) \n",
    "                                     for _ in range(n_layers)])\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [batch size, src len, src hidden]  \n",
    "        \n",
    "        src = self.dropout(src)        \n",
    "        \n",
    "        for layer in self.layers:\n",
    "            \n",
    "            src = layer(src)\n",
    "            \n",
    "        #src = [batch size, src len, hid dim]\n",
    "                  \n",
    "        return src"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.short_term_transformer = TransformerEncoder(input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device)\n",
    "        \n",
    "        self.middle_term_transformer = TransformerEncoder(input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device)\n",
    "        \n",
    "        self.long_term_transformer = TransformerEncoder(input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device)\n",
    "        \n",
    "    \n",
    "    def forward(self, src):\n",
    "        \n",
    "        short_term_encoding = self.short_term_transformer(src)\n",
    "        \n",
    "        middle_term_encoding = self.middle_term_transformer(src)\n",
    "        \n",
    "        long_term_encoding = self.long_term_transformer(src)\n",
    "        \n",
    "        return short_term_encoding, middle_term_encoding, long_term_encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MultiTask(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device):\n",
    "        # input_dim20 hid_dim6\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device)\n",
    "        \n",
    "        self.att_short = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.att_middle = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.att_long = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "    \n",
    "        self.nn_short = nn.Sequential(\n",
    "            nn.Linear(2*input_dim*hid_dim, 30),            \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 3),\n",
    "        )\n",
    "        \n",
    "        self.nn_middle = nn.Sequential(\n",
    "            nn.Linear(2*input_dim*hid_dim, 30),            \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 3),\n",
    "        )\n",
    "        \n",
    "        self.nn_long = nn.Sequential(\n",
    "            nn.Linear(2*input_dim*hid_dim, 30),            \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 3),\n",
    "        )\n",
    "        \n",
    "        self.Tanh_short = nn.Tanh()\n",
    "        self.Tanh_middle = nn.Tanh()\n",
    "        self.Tanh_long = nn.Tanh()\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    \n",
    "    def soft_attention(self, src, tanh):\n",
    "        src = src.view(len(src), -1)\n",
    "        src_h = tanh(src)\n",
    "        src_softmax = self.softmax(src_h)\n",
    "        \n",
    "        src_out = src*src_softmax\n",
    "        \n",
    "        return src_out       \n",
    "        \n",
    "        \n",
    "    def forward(self, srcA, srcB):\n",
    "\n",
    "        short_encodingA, middle_encodingA, long_encodingA = self.encoder(srcA)\n",
    "        short_encodingB, middle_encodingB, long_encodingB = self.encoder(srcB)\n",
    "        \n",
    "        short_encoding = torch.cat([short_encodingA, short_encodingB], dim=1) \n",
    "        middle_encoding = torch.cat([middle_encodingA, middle_encodingB], dim=1)\n",
    "        long_encoding = torch.cat([long_encodingA, long_encodingB], dim=1)\n",
    "        \n",
    "        encoding = torch.cat([short_encoding, middle_encoding, long_encoding], dim=1)\n",
    "\n",
    "        \n",
    "        short_encoding_att = self.att_short(short_encoding, encoding, encoding)        \n",
    "        middle_encoding_att = self.att_middle(middle_encoding, encoding, encoding)\n",
    "        long_encoding_att = self.att_long(long_encoding, encoding, encoding)\n",
    "        \n",
    "\n",
    "        batch_size = len(short_encoding_att[0])\n",
    "#         m1: [10240 x 6], m2: [240 x 30] at\n",
    "        short_score = self.nn_short(short_encoding_att[0].view(batch_size, -1))\n",
    "        middle_score = self.nn_middle(middle_encoding_att[0].view(batch_size, -1))\n",
    "        long_score = self.nn_long(long_encoding_att[0].view(batch_size, -1))\n",
    "        \n",
    "        return short_score, middle_score, long_score\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train and test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f = '/home/ruyao/self_supervised_model/data/encoding_feature.pkl'\n",
    "data = pd.read_pickle(f)\n",
    "data = data.reset_index(drop=True)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "split_date = (datetime.date(2019,1,1), datetime.date(2020,1,1), datetime.date(2021,1,1), datetime.date(2021,10,1))\n",
    "enc_train_data = data[(data['dt']>=split_date[0]) & (data['dt']<split_date[1])].reset_index(drop=True)\n",
    "enc_valid_data = data[(data['dt']>=split_date[1]) & (data['dt']<split_date[2])].reset_index(drop=True)\n",
    "enc_test_data = data[(data['dt']>=split_date[2]) & (data['dt']<split_date[3])].reset_index(drop=True)\n",
    "data.shape, enc_train_data.shape, enc_valid_data.shape, enc_test_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_data_loader(data, batch_size):\n",
    "\n",
    "    X_A = torch.tensor(data['daily20_features_x']).to(torch.float32)\n",
    "    X_B = torch.tensor(data['daily20_features_y']).to(torch.float32)\n",
    "\n",
    "    y1 = torch.tensor(data['corr1_label'])\n",
    "    y2 = torch.tensor(data['corr5_label'])\n",
    "    y3 = torch.tensor(data['corr20_label'])\n",
    "\n",
    "    data_set = TensorDataset(X_A, X_B, y1, y2, y3) \n",
    "    data_loader = DataLoader(data_set, batch_size, shuffle=True, drop_last=False)\n",
    "    \n",
    "    return data_loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "enc_test_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "print('start train data..', datetime.datetime.now())\n",
    "trainDataLoader = build_data_loader(enc_train_data, batch_size)\n",
    "\n",
    "print('start valid data..', datetime.datetime.now())\n",
    "validDataLoader = build_data_loader(enc_valid_data, batch_size)\n",
    "\n",
    "print('start test data..', datetime.datetime.now())\n",
    "testDataLoader = build_data_loader(enc_test_data, batch_size)\n",
    "print('dataload end', datetime.datetime.now())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchsnooper\n",
    "# @torchsnooper.snoop()\n",
    "def enc_train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    epoch_log = {\"loss\":[], \"accuracy\":[]}\n",
    "\n",
    "    short_log = {\"loss\":[], \"accuracy\":[]}\n",
    "    middle_log = {\"loss\":[], \"accuracy\":[]}\n",
    "    long_log = {\"loss\":[], \"accuracy\":[]}\n",
    "\n",
    "    for i, batch in tqdm(enumerate(iterator)):\n",
    "\n",
    "        X_A, X_B, y1, y2, y3 = batch[0], batch[1], batch[2], batch[3], batch[4]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        short_score, middle_score, long_score = model(X_A.to(device), X_B.to(device))   \n",
    "\n",
    "        shape2 = short_score.shape[1]\n",
    "        loss_short = criterion(short_score, y1.to(device))   \n",
    "        loss_middle = criterion(middle_score, y2.to(device)) \n",
    "        loss_long = criterion(long_score, y3.to(device)) \n",
    "\n",
    "        loss = (loss_short+loss_middle+loss_long)/3\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_log[\"loss\"].append(loss.item())\n",
    "        epoch_log[\"accuracy\"].append(accuracy_score(np.round(torch.cat([short_score, middle_score, long_score]).argmax(dim=1).detach().cpu().numpy()), torch.cat([y1, y2, y3]).detach().cpu().numpy()))\n",
    "\n",
    "\n",
    "        short_log[\"loss\"].append(loss_short.item())\n",
    "        short_log[\"accuracy\"].append(accuracy_score(np.round(short_score.argmax(dim=1).detach().cpu().numpy()), y1.detach().cpu().numpy()))\n",
    "\n",
    "        middle_log[\"loss\"].append(loss_middle.item())\n",
    "        middle_log[\"accuracy\"].append(accuracy_score(np.round(middle_score.argmax(dim=1).detach().cpu().numpy()), y2.detach().cpu().numpy()))\n",
    "\n",
    "        long_log[\"loss\"].append(loss_long.item())\n",
    "        long_log[\"accuracy\"].append(accuracy_score(np.round(long_score.argmax(dim=1).detach().cpu().numpy()), y3.detach().cpu().numpy()))\n",
    "\n",
    "        \n",
    "    return epoch_log, short_log, middle_log, long_log"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def enc_eval(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_log = {\"loss\":[], \"accuracy\":[]}\n",
    "    \n",
    "    short_log = {\"loss\":[], \"accuracy\":[]}\n",
    "    middle_log = {\"loss\":[], \"accuracy\":[]}\n",
    "    long_log = {\"loss\":[], \"accuracy\":[]}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in tqdm(enumerate(iterator)):\n",
    "\n",
    "            X_A, X_B, y1, y2, y3 = batch[0], batch[1], batch[2], batch[3], batch[4]\n",
    "\n",
    "            short_score, middle_score, long_score = model(X_A.to(device), X_B.to(device))   \n",
    "\n",
    "            shape2 = short_score.shape[1]\n",
    "            loss_short = criterion(short_score, y1.to(device))   \n",
    "            loss_middle = criterion(middle_score, y2.to(device)) \n",
    "            loss_long = criterion(long_score, y3.to(device)) \n",
    "\n",
    "            loss = (loss_short+loss_middle+loss_long)/3\n",
    "\n",
    "            epoch_log[\"loss\"].append(loss.item())\n",
    "            epoch_log[\"accuracy\"].append(accuracy_score(np.round(torch.cat([short_score, middle_score, long_score]).argmax(dim=1).detach().cpu().numpy()), torch.cat([y1, y2, y3]).detach().cpu().numpy()))\n",
    "\n",
    "\n",
    "            short_log[\"loss\"].append(loss_short.item())\n",
    "            short_log[\"accuracy\"].append(accuracy_score(np.round(short_score.argmax(dim=1).detach().cpu().numpy()), y1.detach().cpu().numpy()))\n",
    "\n",
    "            middle_log[\"loss\"].append(loss_middle.item())\n",
    "            middle_log[\"accuracy\"].append(accuracy_score(np.round(middle_score.argmax(dim=1).detach().cpu().numpy()), y2.detach().cpu().numpy()))\n",
    "\n",
    "            long_log[\"loss\"].append(loss_long.item())\n",
    "            long_log[\"accuracy\"].append(accuracy_score(np.round(long_score.argmax(dim=1).detach().cpu().numpy()), y3.detach().cpu().numpy()))\n",
    "\n",
    "        \n",
    "    return epoch_log, short_log, middle_log, long_log"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 参数修改\n",
    "encoding_model_save_file = '/home/ruyao/self_supervised_model/model/encoding_lr0.0001_epoch25.pt'\n",
    "pic_name = '/home/ruyao/self_supervised_model/model/encoding_lr0.0001_epoch25_drop3_sigmoid_2019-2'\n",
    "\n",
    "# input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device\n",
    "input_dim = 20\n",
    "hid_dim = 6\n",
    "n_layers = 1\n",
    "n_heads = 1\n",
    "pf_dim = 30\n",
    "dropout = 0.3\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "N_EPOCHS = 25\n",
    "\n",
    "encoding_model = MultiTask(input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device).to(device)\n",
    "# criterion = torch.nn.BCELoss()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(encoding_model.parameters(), lr = LEARNING_RATE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoding_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_valid_loss = float('inf')\n",
    "train_log = {'loss':[], \"acc\":[]}\n",
    "val_log = {'loss':[], \"acc\":[]}\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = enc_train(encoding_model, trainDataLoader, optimizer, criterion)\n",
    "    valid_loss = enc_eval(encoding_model, validDataLoader, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)    \n",
    "    \n",
    "    tra_loss = np.mean(train_loss[0]['loss'])\n",
    "    tra_acc = np.mean(train_loss[0]['accuracy'])\n",
    "    val_loss = np.mean(valid_loss[0]['loss'])\n",
    "    val_acc = np.mean(valid_loss[0]['accuracy'])\n",
    "    \n",
    "    train_log['loss'].append(tra_loss)\n",
    "    train_log['acc'].append(tra_acc)\n",
    "    val_log['loss'].append(val_loss)\n",
    "    val_log['acc'].append(val_acc)\n",
    "    \n",
    "    if val_loss < best_valid_loss:\n",
    "        best_valid_loss = val_loss\n",
    "        torch.save(encoding_model.state_dict(), encoding_model_save_file)\n",
    "        print(\"save model\")\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {tra_loss:.3f} | Train Acc: {tra_acc:.3f}')\n",
    "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc:.3f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 模型测试\n",
    "encoding_model.load_state_dict(torch.load(encoding_model_save_file))\n",
    "\n",
    "test_loss = enc_eval(encoding_model, testDataLoader, criterion)\n",
    "\n",
    "te_loss = np.mean(test_loss[0]['loss'])\n",
    "te_acc = np.mean(test_loss[0]['accuracy'])\n",
    "\n",
    "print(f'| Test Loss: {te_loss:.3f} | Test acc: {te_acc:.3f} |')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = torch.ones(20,6)\n",
    "b = torch.randn(20,6)\n",
    "a,b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediciton"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class GRU_Predict(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        \"\"\"\n",
    "        :param input_size:输入维度\n",
    "        :param hidden_size:隐藏层神经元个数\n",
    "        \n",
    "        \"\"\"\n",
    "           \n",
    "        super().__init__()\n",
    "        \n",
    "        self.attention = nn.Linear(20*3*6, 20*6)\n",
    "        \n",
    "        self.GRU = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.Linear = nn.Linear(2*hidden_size, 1)\n",
    "        \n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, s_encoding, m_encoding, l_encoding):\n",
    "        \n",
    "        encoding = torch.cat([s_encoding, m_encoding, l_encoding], dim=1).view(len(s_encoding), -1)\n",
    "        # encoding = [batch_size, short_dim+middle_dim+long_dim=(20*3) * hid_dim=6]\n",
    "        \n",
    "        encoding = self.attention(encoding)\n",
    "        \n",
    "        encoding = encoding.view(len(encoding), -1, 6)\n",
    "        \n",
    "        output, hn = self.GRU(encoding)\n",
    "\n",
    "        out = output[:, -1, :]\n",
    "        # out = [batch, num_directions * hidden_size]\n",
    "\n",
    "        out = self.Linear(out)\n",
    "        \n",
    "        out = self.Sigmoid(out)\n",
    "        \n",
    "        return out        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LSTM_Predict(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        \"\"\"\n",
    "        :param input_size:输入维度\n",
    "        :param hidden_size:隐藏层神经元个数\n",
    "        \n",
    "        \"\"\"\n",
    "           \n",
    "        super().__init__()\n",
    "        \n",
    "        self.attention = nn.Linear(20*3*6, 20*6)\n",
    "        \n",
    "        self.LSTM = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.Linear = nn.Linear(2*hidden_size, 1)\n",
    "        \n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, s_encoding, m_encoding, l_encoding):\n",
    "        \n",
    "        #  encoding = (batch, seq_len, input_size)\n",
    "        # encoing = [batch_size, short_dim/middle_dim/long_dim=(20), hid_dim=6]\n",
    "        \n",
    "        encoding = torch.cat([s_encoding, m_encoding, l_encoding], dim=1).view(len(s_encoding), -1)\n",
    "        # encoding = [batch_size, short_dim+middle_dim+long_dim=(20*3) * hid_dim=6]\n",
    "        \n",
    "        encoding = self.attention(encoding)\n",
    "        \n",
    "        encoding = encoding.view(len(encoding), -1, 6)\n",
    "        \n",
    "        output, hn = self.LSTM(encoding)\n",
    "        \n",
    "        # output =  (batch, seq_len, num_directions * hidden_size)\n",
    "        # hn =  (batch, num_layers * num_directions, hidden_size)\n",
    "        \n",
    "        out = output[:, -1, :]\n",
    "        # out = [batch, num_directions * hidden_size]\n",
    "        \n",
    "        \n",
    "        out = self.Linear(out)\n",
    "        \n",
    "        out = self.Sigmoid(out)\n",
    "        \n",
    "        return out        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f = '/home/ruyao/self_supervised_model/data/daily_feature-2.pkl'\n",
    "daily_df = pd.read_pickle(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "split_date = (datetime.date(2019,1,1), datetime.date(2020,1,1), datetime.date(2021,1,1), datetime.date(2021,10,1))\n",
    "pre_train_data = daily_df[(daily_df['dt']>=split_date[0]) & (daily_df['dt']<split_date[1])].reset_index(drop=True)\n",
    "pre_valid_data = daily_df[(daily_df['dt']>=split_date[1]) & (daily_df['dt']<split_date[2])].reset_index(drop=True)\n",
    "pre_test_data = daily_df[(daily_df['dt']>=split_date[2]) & (daily_df['dt']<split_date[3])].reset_index(drop=True)\n",
    "daily_df.shape, pre_train_data.shape, pre_valid_data.shape, pre_test_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_data_loader_regression(data, batch_size, shuffle):\n",
    "\n",
    "    X = torch.tensor(data['daily20_features']).to(torch.float32)\n",
    "\n",
    "    y1 = torch.tensor(data['close_rtn_rank']).to(torch.float32)\n",
    "    y2 = torch.tensor(data['SR5_rank']).to(torch.float32)\n",
    "    y3 = torch.tensor(data['SR20_rank']).to(torch.float32)\n",
    "    y4 = torch.tensor(data['5_day_rtn_rank']).to(torch.float32)\n",
    "    y5 = torch.tensor(data['20_day_rtn_rank']).to(torch.float32)\n",
    "    \n",
    "    data_set = TensorDataset(X, y1, y2, y3, y4, y5) \n",
    "    data_loader = DataLoader(data_set, batch_size, shuffle=shuffle, drop_last=False)\n",
    "    \n",
    "    return data_loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('start train data..', datetime.datetime.now())\n",
    "trainLoader = build_data_loader_regression(pre_train_data, 256, True)\n",
    "\n",
    "print('start valid data..', datetime.datetime.now())\n",
    "validLoader = build_data_loader_regression(pre_valid_data, 256, True)\n",
    "\n",
    "print('start test data..', datetime.datetime.now())\n",
    "testLoader = build_data_loader_regression(pre_test_data, 256, False)\n",
    "print('dataload end', datetime.datetime.now())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pre_train(model, encoding_model, iterator, optimizer, criterion):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    epoch_log = {\"loss\":[], \"accuracy\":[], \"f1_score\":[], \"recall_score\":[]}\n",
    "\n",
    "    encoding_model.eval()\n",
    "\n",
    "    for i, batch in tqdm(enumerate(iterator)):\n",
    "\n",
    "        X, y1, y2, y3, y4, y5 = batch[0], batch[1], batch[2], batch[3], batch[4], batch[5]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        s_encoding, m_encoding, l_encoding = encoding_model.encoder(X.to(device))\n",
    "\n",
    "        score = model(s_encoding, m_encoding, l_encoding)           \n",
    "\n",
    "        loss = criterion(score, y1.view(-1, 1).to(device))    \n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_log[\"loss\"].append(loss.item())\n",
    "\n",
    "    return epoch_log"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pre_eval(model, encoding_model, iterator, criterion, result=False):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    epoch_log = {\"loss\":[], \"accuracy\":[], \"f1_score\":[], \"recall_score\":[]}\n",
    "\n",
    "    encoding_model.eval()\n",
    "    \n",
    "    score_numpy = np.array([])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, batch in tqdm(enumerate(iterator)):\n",
    "\n",
    "            X, y1, y2, y3, y4, y5 = batch[0], batch[1], batch[2], batch[3], batch[4], batch[5]\n",
    "\n",
    "            s_encoding, m_encoding, l_encoding = encoding_model.encoder(X.to(device))\n",
    "\n",
    "            score = model(s_encoding, m_encoding, l_encoding)      \n",
    "\n",
    "            score_numpy = np.append(score_numpy, score.detach().cpu().numpy())\n",
    "\n",
    "            loss = criterion(score, y1.view(-1, 1).to(device))    \n",
    "\n",
    "            epoch_log[\"loss\"].append(loss.item())\n",
    "\n",
    "    if result==True:\n",
    "        return epoch_log, score_numpy\n",
    "    else:\n",
    "        return epoch_log"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoding_model_load_file = encoding_model_save_file\n",
    "prediction_model_save_file = '/home/ruyao/self_supervised_model/model/prediction_lr0.0001_epoch25_rankrg_closertn-encoding_lr0.0001-2.pt'\n",
    "pic_name_pre = '/home/ruyao/self_supervised_model/model/prediction_lr0.0001_epoch25_rankrg_closertn-encoding_lr0.0001-2'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_size = 6  # 表征维度\n",
    "hidden_size = 30  # 隐层神经元个数\n",
    "num_layers = 2  #隐层层数\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "prediction_model = GRU_Predict(input_size, hidden_size, num_layers).to(device)\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "\n",
    "criterion_predict = torch.nn.MSELoss()\n",
    "optimizer_predict = torch.optim.Adam(prediction_model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N_EPOCHS = 25\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "train_log = {'loss':[], \"acc\":[], \"f1\":[], \"recall\":[]}\n",
    "val_log = {'loss':[], \"acc\":[], \"f1\":[], \"recall\":[]}\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss = pre_train(prediction_model, encoding_model, trainLoader, optimizer_predict, criterion_predict)\n",
    "    valid_loss = pre_eval(prediction_model, encoding_model, validLoader, criterion_predict)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)    \n",
    "    \n",
    "    tra_loss = np.mean(train_loss['loss'])\n",
    "    val_loss = np.mean(valid_loss['loss'])\n",
    "    train_log['loss'].append(tra_loss)\n",
    "    val_log['loss'].append(val_loss)\n",
    "    \n",
    "    if val_loss < best_valid_loss:\n",
    "        best_valid_loss = val_loss\n",
    "        torch.save(prediction_model.state_dict(), prediction_model_save_file)\n",
    "        print(\"save model\")\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {tra_loss:.3f} ')\n",
    "    print(f'\\t Val. Loss: {val_loss:.3f} ')\n",
    "                                                                               "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = np.arange(1,N_EPOCHS+1) \n",
    "y1 =  train_log['loss']\n",
    "y2 = val_log['loss']\n",
    "plt.title(\"loss\") \n",
    "plt.xlabel(\"Epochs\") \n",
    "plt.plot(x,y1, label=\"train loss\") \n",
    "plt.plot(x,y2, label=\"val loss\") \n",
    "plt.legend()\n",
    "plt.savefig(pic_name_pre + '_loss.jpg')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load已经训练好的参数\n",
    "encoding_model_save_file = \"/home/ruyao/self_supervised_model/model/prediction_lr0.0001_epoch25_rankrg_closertn-encoding_lr0.0001.pt\"\n",
    "prediction_model.load_state_dict(torch.load(encoding_model_save_file))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validLoader = build_data_loader_regression(pre_valid_data, 256, False)\n",
    "test_val_loss, test_val_score_np = pre_eval(prediction_model, encoding_model, validLoader, criterion_predict, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainLoader = build_data_loader_regression(pre_train_data, 256, False)\n",
    "train_loss, train_score_np = pre_eval(prediction_model, encoding_model, trainLoader, criterion_predict, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 模型测试\n",
    "\n",
    "test_loss, score_np = pre_eval(prediction_model, encoding_model, testLoader, criterion_predict, True)\n",
    "\n",
    "te_loss = np.mean(test_loss['loss'])\n",
    "\n",
    "print(f'| Test Loss: {te_loss:.3f} ')\n",
    "# print(f'| Test Loss: {te_loss:.3f} | Test acc: {te_acc:.3f} | Test f1: {te_f1:.3f}| Test recall: {te_recall:.3f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.sum(test_loss['loss']+test_val_loss['loss'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pre_test_data['predict_score'] = score_np.reshape(-1, 1)\n",
    "df = pre_test_data[['stock_code', \"dt\", \"predict_score\"]]\n",
    "df.columns = ['stock_code', \"dt\", \"score\"]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pre_valid_data['predict_score'] = test_val_score_np.reshape(-1, 1)\n",
    "df2 = pre_valid_data[['stock_code', \"dt\", \"predict_score\"]]\n",
    "df2.columns = ['stock_code', \"dt\", \"score\"]\n",
    "df2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pre_train_data['predict_score'] = train_score_np.reshape(-1, 1)\n",
    "df3 = pre_train_data[['stock_code', \"dt\", \"predict_score\"]]\n",
    "df3.columns = ['stock_code', \"dt\", \"score\"]\n",
    "df3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_df = pd.concat([df3, df2, df], axis=0)\n",
    "result_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_root_dir = \"/home/ruyao/self_supervised_model/result/prediction_lr0.0001_epoch25_rankrg_closertn-encoding_lr0.0001-2019_2021\"\n",
    "if not os.path.exists(result_root_dir):\n",
    "    os.mkdir(result_root_dir)\n",
    "if not os.path.exists(result_root_dir+\"/prediction\"):\n",
    "    os.mkdir(result_root_dir+\"/prediction\")\n",
    "    \n",
    "for key, val in result_df.groupby(\"dt\"):\n",
    "    val.to_csv(f\"{result_root_dir}/prediction/{key}.csv\", index = False)\n",
    "    print(f\"{result_root_dir}/{key}.csv生成！\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}