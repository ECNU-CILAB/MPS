{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['config']='/home/ruyao/database.yaml'\n",
    "from qsdata import kddb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "from qsdata.api import get_vwap, get_sw_industry\n",
    "from datetime import date, timedelta\n",
    "from qsdata.api import get_previous_trading_date,index_components,get_trading_dates,get_next_trading_date,get_price\n",
    "import copy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dt = [\"20190417\"]\n",
    "for i in range(20):\n",
    "    test_dt.append(get_next_trading_date(test_dt[-1]))\n",
    "test_dt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from multiprocessing import Process"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 取沪深300和中证500的成分股\n",
    "stockcodes = index_components('000905.SH', datetime.date(2019,1,1)) + index_components('000300.SH',datetime.date(2019,1,1))\n",
    "features = [\"open\", \"close\", \"high\", \"low\", \"turnover\", \"volume\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s_dt = \"20180101\"\n",
    "e_dt = \"20211001\"\n",
    "# s_dt = \"20141101\"\n",
    "train_set = [\"20180101\", \"20181231\"]\n",
    "valid_set = [\"20190101\", \"20191231\"]\n",
    "test_set = [\"20200101\", \"20211001\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'000049.sz' in stockcodes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 获取日线数据\n",
    "## Obain daily data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 获取日线数据\n",
    "daily_data = get_price(None,\n",
    "              start_date=s_dt,\n",
    "              end_date=e_dt,\n",
    "              fields=features,\n",
    "              frequency='1d')\n",
    "\n",
    "daily_data = daily_data.reset_index()\n",
    "\n",
    "daily_data['dt'] = daily_data['dt'].apply(lambda x: x.date())\n",
    "daily_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daily_data = daily_data.loc[(daily_data['turnover']>0) & (daily_data['volume']>0)]\n",
    "daily_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 对缺失日期进行补全，得到nan值\n",
    "std_list = []\n",
    "\n",
    "for s in stockcodes:\n",
    "    for dt in get_trading_dates(s_dt,e_dt):\n",
    "        std_dict = {'stock_code':s, 'dt':dt}\n",
    "        std_list.append(std_dict)\n",
    "std_df = pd.DataFrame(std_list)\n",
    "\n",
    "daily_data = pd.merge(daily_data, std_df, on=['stock_code', 'dt'], how='outer')\n",
    "daily_data = daily_data.sort_values(by=[\"stock_code\", \"dt\"]).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 构建标签\n",
    "## Construct label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daily_df = daily_data.copy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 未来20天价格\n",
    "for d in range(1, 21):\n",
    "    daily_df['close_t' + str(d)] = daily_df.groupby('stock_code')['close'].shift(-d)\n",
    "daily_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daily_df['close_t0'] = daily_df['close']\n",
    "daily_df = daily_df.dropna().reset_index(drop=True)\n",
    "daily_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daily_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daily_df['5_day_rtn'] = daily_df['close_t5']/daily_df['close']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daily_df['20_day_rtn'] = daily_df['close_t20']/daily_df['close']\n",
    "daily_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 计算夏普比率\n",
    "for t in range(1, 21):\n",
    "    base_close_label = \"close\" if t==1 else \"close_t\" + str(t-1)\n",
    "    close_label = \"close_t\" + str(t)\n",
    "    rtn_label = \"rtn_t\" + str(t)\n",
    "    daily_df[rtn_label] = daily_df[close_label]/daily_df[base_close_label]\n",
    "    \n",
    "for SR_len in [5, 20]:\n",
    "    att = ['rtn_t'+str(i) for i in range(1, SR_len+1)]\n",
    "    daily_df['SR'+str(SR_len)] = daily_df[att].mean(axis=1)/daily_df[att].std(axis=1)\n",
    "\n",
    "daily_df['close_rtn'] = daily_df['rtn_t1']\n",
    "daily_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SR排名的标签\n",
    "# 分数从小到大排列\n",
    "daily_df['close_rtn_rank'] = daily_df.groupby('dt')['close_rtn'].rank(method='min')/max(daily_df.groupby('dt')['close_rtn'].rank(method='min'))\n",
    "daily_df['close_rtn_label'] = daily_df['close_rtn_rank'] .apply(lambda x: 1 if x>=2/3 else (0 if x<=1/3 else -1))\n",
    "\n",
    "\n",
    "daily_df['SR5_rank'] = daily_df.groupby('dt')['SR5'].rank(method='min')/max(daily_df.groupby('dt')['SR5'].rank(method='min'))\n",
    "daily_df['SR5_label'] = daily_df['SR5_rank'] .apply(lambda x: 1 if x>=2/3 else (0 if x<=1/3 else -1))\n",
    "\n",
    "daily_df['SR20_rank'] = daily_df.groupby('dt')['SR20'].rank(method='min')/max(daily_df.groupby('dt')['SR20'].rank(method='min'))\n",
    "daily_df['SR20_label'] = daily_df['SR20_rank'] .apply(lambda x: 1 if x>=2/3 else (0 if x<=1/3 else -1))\n",
    "daily_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daily_df['5_day_rtn_rank'] = daily_df.groupby('dt')['5_day_rtn'].rank(method='min')/max(daily_df.groupby('dt')['5_day_rtn'].rank(method='min'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daily_df['20_day_rtn_rank'] = daily_df.groupby('dt')['20_day_rtn'].rank(method='min')/max(daily_df.groupby('dt')['20_day_rtn'].rank(method='min'))\n",
    "daily_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 正则化\n",
    "## Regularization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_next_month(dt):\n",
    "    if dt.month == 12:\n",
    "        return date(dt.year + 1, 1, 1)\n",
    "    else:\n",
    "        return date(dt.year, dt.month + 1, 1)\n",
    "\n",
    "\n",
    "def filter_extreme_MAD(series, n=5):  # MAD:中位数去极值\n",
    "    median = np.percentile(series, 50)\n",
    "    new_median = np.percentile((series - median).abs(), 50)\n",
    "    max_range = median + n * new_median\n",
    "    min_range = median - n * new_median\n",
    "    return np.clip(series, min_range, max_range)\n",
    "\n",
    "\n",
    "def filter_extreme_3sigma(series, n=3):  # 3 sigma\n",
    "    mean = series.mean()\n",
    "    std = series.std()\n",
    "    max_range = mean + n * std\n",
    "    min_range = mean - n * std\n",
    "    return np.clip(series, min_range, max_range)\n",
    "\n",
    "\n",
    "def filter_extreme_percentile(series, min=0.025, max=0.975):  # 百分位法\n",
    "    series = series.sort_values()\n",
    "    q = series.quantile([min, max])\n",
    "    return np.clip(series, q.iloc[0], q.iloc[1])\n",
    "\n",
    "\n",
    "def standardize_zscore(series):\n",
    "    std = series.std()\n",
    "    mean = series.mean()\n",
    "    # 如果标准差为0的series，全部返回0\n",
    "    if std == 0:\n",
    "        return series - mean\n",
    "    else:\n",
    "        return (series - mean) / std\n",
    "\n",
    "\n",
    "def standardize_normal(series):\n",
    "    min_v = series.min()\n",
    "    max_v = series.max()\n",
    "    return (series - min_v) / (max_v - min_v)\n",
    "\n",
    "\n",
    "def ds_filter_extreme_3sigma(series, n=3, min_range=None, max_range=None):  # 3 sigma\n",
    "    if min_range is not None and max_range is not None:\n",
    "        return np.clip(series, min_range, max_range), min_range, max_range\n",
    "    else:\n",
    "        mean = series.mean()\n",
    "        std = series.std()\n",
    "        max_range = mean + n * std\n",
    "        min_range = mean - n * std\n",
    "        return np.clip(series, min_range, max_range), min_range, max_range\n",
    "\n",
    "\n",
    "def ds_filter_extreme_MAD(series, n=5, min_range=None, max_range=None):  # MAD:中位数去极值\n",
    "    if min_range is not None and max_range is not None:\n",
    "        return np.clip(series, min_range, max_range), min_range, max_range\n",
    "    else:\n",
    "        median = np.percentile(series, 50)\n",
    "        new_median = np.percentile((series - median).abs(), 50)\n",
    "        max_range = median + n * new_median\n",
    "        min_range = median - n * new_median\n",
    "        return np.clip(series, min_range, max_range), min_range, max_range\n",
    "\n",
    "\n",
    "def ds_standardize_zscore(series, mean=None, std=None):\n",
    "    if mean is not None and std is not None:\n",
    "        if std != 0:\n",
    "            return (series - mean) / std, mean, std\n",
    "        else:\n",
    "            return (series - mean), mean, std\n",
    "    else:\n",
    "        std = series.std()\n",
    "        mean = series.mean()\n",
    "        # 如果标准差为0的series，全部返回0\n",
    "        if std == 0:\n",
    "            return series - mean, mean, std\n",
    "        else:\n",
    "            return (series - mean) / std, mean, std\n",
    "        \n",
    "        \n",
    "        \n",
    "# 正则化\n",
    "\n",
    "def normalization(daily_data, split_dt, labels=False, d_data=True, return_split=False):\n",
    "\n",
    "\n",
    "    train_daily_df = daily_data[daily_data[\"dt\"]<=split_dt]\n",
    "    test_daily_df = daily_data[daily_data[\"dt\"]>split_dt]\n",
    "    \n",
    "    if d_data:\n",
    "        features = [\"close\",\"open\",\"high\",\"low\",\"volume\",\"turnover\"]\n",
    "    else:\n",
    "        features = [\"close\",\"open\",\"high\",\"low\",\"volume\",\"amount\"]\n",
    "        \n",
    "    if labels:\n",
    "        features = labels\n",
    "    \n",
    "    for f in features:\n",
    "        d = {}\n",
    "        train_daily_df[f], min_range, max_range = ds_filter_extreme_3sigma(train_daily_df[f])\n",
    "        train_daily_df[f], mean, std = ds_standardize_zscore(train_daily_df[f])\n",
    "        d[\"min_range\"], d['max_range'], d['mean'], d['std'] = min_range, max_range, mean, std\n",
    "        test_daily_df[f], _, _ = ds_filter_extreme_MAD(test_daily_df[f], min_range = min_range, max_range = max_range)\n",
    "        test_daily_df[f], _, _ = ds_standardize_zscore(test_daily_df[f], mean, std)\n",
    "\n",
    "    print(\"成功去极值、标准化\")\n",
    "    \n",
    "    if return_split:\n",
    "        return train_daily_df, test_daily_df, d\n",
    "    else:\n",
    "        return pd.concat((train_daily_df, test_daily_df))\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 去inf和nan值\n",
    "def replace_inf(df, labels):\n",
    "    for label in labels:\n",
    "        df[label] = df[label].apply(lambda x: np.nan if np.isinf(x) else x)\n",
    "    return df\n",
    "daily_df = replace_inf(daily_df, ['close_rtn', 'SR5', 'SR20'])\n",
    "daily_df = daily_df.dropna().reset_index(drop=True)\n",
    "daily_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for f in ['SR5', 'SR20']:\n",
    "    daily_df[f] = filter_extreme_percentile(daily_df[f], 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daily_df['close_rtn'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daily_df['SR5'].loc[daily_df['SR5']>113965]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daily_df['SR5'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daily_df['SR20'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daily_df[daily_df['SR20']>129]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 标签标准化\n",
    "labels = ['open', 'close', 'high', 'low', 'turnover', 'volume']\n",
    "\n",
    "daily_df_normalized = normalization(daily_df, datetime.datetime.strptime(train_set[1], \"%Y%m%d\").date(), labels)\n",
    "daily_df_normalized\n",
    "\n",
    "# daily_feature_df_normalized = normalization(daily_feature_df, datetime.datetime.strptime(train_set[1], \"%Y%m%d\").date(), ['close_rtn', 'SR5', 'SR20'])\n",
    "# daily_feature_df_normalized"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 数值分析 data analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "\n",
    "# test_open = daily_df_normalized['close_rtn'].value_counts()\n",
    "# plt.scatter(test_open.index,test_open.values)\n",
    "plt.hist(daily_df['SR5_label'])\n",
    "daily_df_normalized['SR5_label'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.hist(daily_df['SR20_label'])\n",
    "daily_df_normalized['SR20_label'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.hist(daily_df['close_rtn'])\n",
    "daily_df_normalized['close_rtn'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train_d, test_d, d = normalization(daily_df, datetime.datetime.strptime(train_set[1], \"%Y%m%d\").date(), ['close_rtn', 'SR5', 'SR20'], return_split=True)\n",
    "# d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 构建日线数据\n",
    "## Construct daily data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daily_df_normalized = daily_df_normalized.dropna()\n",
    "daily_df_normalized['features'] = daily_df_normalized[['open', 'close', 'high', 'low', 'turnover', 'volume']].apply(lambda x: list(x.values), axis=1)\n",
    "daily_df_normalized"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 对缺失日期进行补全，得到nan值\n",
    "std_list = []\n",
    "\n",
    "for s in stockcodes:\n",
    "    for dt in get_trading_dates(s_dt,e_dt):\n",
    "        std_dict = {'stock_code':s, 'dt':dt}\n",
    "        std_list.append(std_dict)\n",
    "std_df = pd.DataFrame(std_list)\n",
    "\n",
    "daily_feature_df = pd.merge(daily_df_normalized, std_df, on=['stock_code', 'dt'], how='outer')\n",
    "daily_feature_df = daily_feature_df.sort_values(by=[\"stock_code\", \"dt\"]).reset_index(drop=True)\n",
    "daily_feature_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 构建20维\n",
    "for i in range(1, 20):\n",
    "    daily_feature_df['features-'+str(i)] = daily_feature_df.groupby('stock_code')['features'].shift(i)\n",
    "    \n",
    "daily_feature_df = daily_feature_df.dropna().reset_index(drop=True)\n",
    "daily_feature_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daily_feature_df['daily20_features'] = daily_feature_df[['features']+['features-'+str(i) for i in range(1, 20)]].apply(lambda x: np.array(list(x.values)), axis=1)\n",
    "daily_feature_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daily_feature_df['close_rtn'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daily_feature_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 预测模型数据存储，最终需要的\n",
    "daily_feature_df[['stock_code', 'dt', 'daily20_features', 'close_rtn', 'SR5', 'SR20', 'close_rtn_rank', 'close_rtn_label', 'SR5_rank',\n",
    "       'SR5_label', 'SR20_rank', 'SR20_label', '5_day_rtn_rank', '20_day_rtn_rank']].to_pickle('/home/ruyao/self_supervised_model/data/daily_feature-2.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daily_feature_df['stock_code'].value_counts().describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encoding模型数据建立-相关系数法\n",
    "\n",
    "## Construct data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "daily_feature_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pair_daily_df = daily_feature_df[['stock_code', 'dt','close_t0', 'close_t1', 'close_t2', 'close_t3', 'close_t4', 'close_t5', 'close_t6',\n",
    "       'close_t7', 'close_t8', 'close_t9', 'close_t10', 'close_t11',\n",
    "       'close_t12', 'close_t13', 'close_t14', 'close_t15', 'close_t16',\n",
    "       'close_t17', 'close_t18', 'close_t19', 'close_t20', 'daily20_features']].copy()\n",
    "# pair_daily_df['pair_stock_code'] = pair_daily_df['stock_code'].apply(lambda x: random.choice(stockcodes))\n",
    "pair_daily_df['pair_stock_code'] = pair_daily_df['stock_code'].apply(lambda x: random.choice([k for k in stockcodes if k not in [x]]))\n",
    "\n",
    "pair_daily_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pair_daily_df['close_array20'] = pair_daily_df[['close_t0', 'close_t1', 'close_t2', 'close_t3', 'close_t4', 'close_t5', 'close_t6',\n",
    "       'close_t7', 'close_t8', 'close_t9', 'close_t10', 'close_t11',\n",
    "       'close_t12', 'close_t13', 'close_t14', 'close_t15', 'close_t16',\n",
    "       'close_t17', 'close_t18', 'close_t19', 'close_t20']].apply(lambda x: list(x.values), axis=1)\n",
    "pair_daily_df['close_array5'] = pair_daily_df[['close_t0', 'close_t1', 'close_t2', 'close_t3', 'close_t4', 'close_t5']].apply(lambda x: list(x.values), axis=1)\n",
    "pair_daily_df['close_array1'] = pair_daily_df[['close_t0', 'close_t1']].apply(lambda x: list(x.values), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pair_daily_df = pd.merge(pair_daily_df, pair_daily_df, left_on=[\"pair_stock_code\", \"dt\"], right_on=[\"stock_code\", \"dt\"])\n",
    "pair_daily_df = pair_daily_df.dropna().reset_index(drop=True)\n",
    "pair_daily_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pair_daily_df[['stock_code_x', 'stock_code_y', 'dt','daily20_features_x', 'daily20_features_y', 'close_array20_y']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "# 函数：计算相关系数\n",
    "def calc_corr(a, b):\n",
    "    a_avg = sum(a)/len(a)\n",
    "    b_avg = sum(b)/len(b)\n",
    " \n",
    "    # 计算分子，协方差————按照协方差公式，本来要除以n的，由于在相关系数中上下同时约去了n，于是可以不除以n\n",
    "    cov_ab = sum([(x - a_avg)*(y - b_avg) for x,y in zip(a, b)])\n",
    " \n",
    "    # 计算分母，方差乘积————方差本来也要除以n，在相关系数中上下同时约去了n，于是可以不除以n\n",
    "    sum1 = sum([(x - a_avg)**2 for x in a])\n",
    "    sum2 = sum([(x - b_avg)**2 for x in b])\n",
    "    sq = math.sqrt(sum1*sum2)\n",
    "\n",
    "    if sum1==0 and sum2==0:\n",
    "        return 1.0\n",
    "    elif sum1==0 or sum2==0:\n",
    "        return 0.0\n",
    "        \n",
    "    corr_factor = cov_ab/sq    \n",
    " \n",
    "    return corr_factor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pair_daily_df['corr20'] = pair_daily_df.apply(lambda x: calc_corr(x['close_array20_x'], x['close_array20_y']), axis=1)\n",
    "pair_daily_df['corr5'] = pair_daily_df.apply(lambda x: calc_corr(x['close_array5_x'], x['close_array5_y']), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pair_daily_df['corr1'] = pair_daily_df.apply(lambda x: calc_corr(x['close_array1_x'], x['close_array1_y']), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pair_daily_df[['corr20', 'corr5', 'corr1']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 三分类标签，不相关0 正相关1 负相关2\n",
    "pair_daily_df['corr1_label'] = pair_daily_df['corr1'] .apply(lambda x: 1 if x>=2/3 else (2 if x<=-1/3 else 0))\n",
    "pair_daily_df['corr5_label'] = pair_daily_df['corr5'] .apply(lambda x: 1 if x>=0.5 else (2 if x<=-0.5 else 0))\n",
    "pair_daily_df['corr20_label'] = pair_daily_df['corr20'] .apply(lambda x: 1 if x>=0.5 else (2 if x<=-0.5 else 0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "q = pair_daily_df['corr5'].quantile([1/4, 3/4])\n",
    "q"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pair_daily_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pair_daily_df['corr1_label']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 存储encoding数据，最终使用的数据\n",
    "pair_daily_df[['stock_code_x', 'stock_code_y', 'dt', 'daily20_features_x', 'daily20_features_y', 'corr20',\n",
    "       'corr5', 'corr1', 'corr1_label', 'corr5_label', 'corr20_label']].to_pickle('/home/ruyao/self_supervised_model/data/encoding_feature.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 对label进行正则化\n",
    "\n",
    "pair_daily_df_normalized = normalization(pair_daily_df, datetime.datetime.strptime(train_set[1], \"%Y%m%d\").date(), ['corr20', 'corr5', 'corr1'])\n",
    "pair_daily_df_normalized"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 存储encoding数据\n",
    "# pair_daily_df_normalized[['stock_code_x', 'stock_code_y', 'dt', 'daily20_features_x', 'daily20_features_y', 'corr20',\n",
    "#        'corr5', 'corr1']].to_pickle('/mnt/disk1/min_data/ruyao/v4/data/encoding_feature_normalized.pkl')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encoding模型数据建立 (v3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pair_daily_df = daily_feature_df[['stock_code', 'dt', 'rtn_t1', 'rtn_t2',\n",
    "       'rtn_t3', 'rtn_t4', 'rtn_t5', 'rtn_t6', 'rtn_t7', 'rtn_t8', 'rtn_t9',\n",
    "       'rtn_t10', 'rtn_t11', 'rtn_t12', 'rtn_t13', 'rtn_t14', 'rtn_t15',\n",
    "       'rtn_t16', 'rtn_t17', 'rtn_t18', 'rtn_t19', 'rtn_t20','daily20_features']].copy()\n",
    "# pair_daily_df['pair_stock_code'] = pair_daily_df['stock_code'].apply(lambda x: random.choice(stockcodes))\n",
    "pair_daily_df['pair_stock_code'] = pair_daily_df['stock_code'].apply(lambda x: random.choice([k for k in stockcodes if k not in [x]]))\n",
    "\n",
    "pair_daily_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pair_daily_df = pd.merge(pair_daily_df, pair_daily_df, left_on=[\"pair_stock_code\", \"dt\"], right_on=[\"stock_code\", \"dt\"])\n",
    "\n",
    "pair_daily_df = pair_daily_df.dropna().reset_index(drop=True)\n",
    "pair_daily_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def count_diff(label, n):\n",
    "    pair_daily_df[label] = 0\n",
    "    for i in range(1,n):    \n",
    "        x = 'rtn_t'+str(i) + '_x'\n",
    "        y = 'rtn_t'+str(i) + '_y'\n",
    "        pair_daily_df[label] += pair_daily_df.apply(lambda df: 1 if ( (df[x]>1 and df[y]>1) or (df[x]<1 and df[y]<1) ) else 0, axis=1) # 1pair_df[x]//1) * pair_df[y]//1\n",
    "\n",
    "count_diff('sum_rtn_diff20', 21)\n",
    "count_diff('sum_rtn_diff', 6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pair_daily_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pair_daily_df['']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pair_daily_df['co_rtn_label1'] = pair_daily_df.apply(lambda df: 1 if ( (df['rtn_t1_x']>1 and df['rtn_t1_y']>1) or (df['rtn_t1_x']<1 and df['rtn_t1_y']<1) ) else 0, axis=1)\n",
    "\n",
    "pair_daily_df['co_rtn_label5'] = pair_daily_df['sum_rtn_diff'].apply(lambda x: 1 if x>=3 else 0)\n",
    "pair_daily_df['co_rtn_label20'] = pair_daily_df['sum_rtn_diff20'].apply(lambda x: 1 if x>=13 else 0)\n",
    "pair_daily_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pair_daily_df['co_rtn_label20'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pair_daily_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 存储encoding数据\n",
    "pair_daily_df[['stock_code_x', 'stock_code_y', 'dt', 'daily20_features_x', 'daily20_features_y', 'co_rtn_label1',\n",
    "       'co_rtn_label5', 'co_rtn_label20']].to_pickle('/mnt/disk1/min_data/ruyao/v3/data/encoding_feature-2.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}